Specification Document1. IntroductionProject Name: Meeting AnalyzerOverview:This application is designed to help users record audio from meetings (e.g., Google Meet) and transcribe the audio into text. Built as a web-based solution using Flutter Web, the app leverages browser capabilities (such as getDisplayMedia for capturing system audio) and JavaScript interop for recording. Transcription can be performed either using an offline model (e.g., Whisper or Vosk) or through a cloud-based API. Additional planned features include transcript summarization and prompt-based analysis to further enhance usability.2. Purpose & ScopePurpose:- Provide a lightweight, cross-platform solution for recording meeting audio (both system audio and microphone) and generating transcriptions.- Enable users to export recordings and transcripts in multiple formats (TXT, DOC, JSON).- In future iterations, include transcript summarization and prompt-based functions for deeper analysis or follow-up actions.Scope:- Develop a web-based application that runs in modern browsers (primarily Chromium-based) using Flutter.- Implement functionality to capture audio directly from a browser tab or via screen sharing.- Support local storage and export of audio files and transcriptions.- Offer both real-time (if feasible) and post-processing transcription capabilities.- Ensure the solution is for personal use, emphasizing privacy by keeping all data local.3. Functional Requirements3.1 Audio Recording- Microphone Recording:- Request permission and record audio from the device's microphone using navigator.mediaDevices.getUserMedia({ audio: true }).- Allow users to start, pause, and stop recordings.- System/Tab Audio Recording:- Use navigator.mediaDevices.getDisplayMedia({ video: true, audio: true }) to capture a specific tab or screen with audio.- Provide clear instructions for the user on selecting the correct source (e.g., the meeting tab) and ensuring “Share audio” is enabled.3.2 Audio Mixing (Optional)- Combined Streams:- Merge microphone and system audio streams using the Web Audio API if needed.- Allow configuration options to record one or both streams simultaneously.3.3 Transcription- Post-Processing Transcription:- Enable users to submit a recorded audio file for transcription after the session.- Integrate with an offline transcription engine (such as Whisper or Vosk) or use a cloud-based API (e.g., Google Speech-to-Text) for processing.- Real-Time Transcription (Optional):- Provide a live transcription view using a streaming API if system hardware allows and if the user opts in.- Language & Accuracy Settings:- Allow selection of the language (default: English).- Optionally enable switching between a more resource-intensive model for higher accuracy and a lightweight model for speed.3.4 Data Storage & Export- Local Storage:- Save audio recordings and transcriptions locally on the user’s machine.- Organize recordings by session with date/time stamps.- Export Options:- Allow users to export transcripts as TXT, DOC, or JSON.- Provide a “download” feature for audio files (e.g., WebM or WAV format).3.5 User Notifications and Status- Feedback:- Show status indicators (recording, paused, stopped).- Provide error notifications (e.g., if microphone access is denied or if system audio capture fails).3.6 Future Functionalities- Transcript Summarization:- Implement a feature that automatically generates a concise summary of the transcript.- Use Natural Language Processing (NLP) models to extract key points and generate summary text.- Prompt-Based Analysis:- Enable users to input custom prompts (e.g., “What were the action items?” or “Summarize decisions made during the meeting”) which trigger context-aware analysis of the transcript.- Integrate with AI models (open-source or cloud-based) to return prompt-specific insights or follow-up actions based on the meeting content.4. Non-Functional Requirements- Privacy:- All audio and transcription data should be stored locally and not transmitted without explicit user action.- Performance:- The application should work efficiently within browser limitations.- Transcription and summarization (if performed in real time) should have minimal latency.- Compatibility:- Support modern browsers, with primary functionality on Chromium-based browsers (Chrome, Edge).- User Experience:- Simple, intuitive UI built using Flutter.- Clear instructions for permission requests and recording procedures.- Scalability:- The application is for personal use; hence, scalability is limited to the end user’s device capabilities.5. Technology StackFrontend- Flutter Web:- Build the user interface.- Provide cross-platform capabilities if extended later.- JavaScript Interop:- Use dart:js to interact with browser APIs for audio recording (MediaRecorder, getDisplayMedia).Audio Capture & Processing- Browser APIs:- getUserMedia for microphone access.- getDisplayMedia for capturing screen/tab audio with audio.- Web Audio API for stream mixing (if required).Transcription Engine (Options)- Offline:- OpenAI Whisper or Vosk integrated via a backend service or WebAssembly (if feasible on the client).- Cloud (Optional):- Google Speech-to-Text API or other cloud-based transcription services.Data Management- Local File Handling:- Use browser APIs (FileSaver, IndexedDB, or the File System Access API) for storing and exporting files.Future NLP Capabilities- Summarization & Prompt Analysis:- Integration of NLP libraries or APIs (such as Hugging Face models, OpenAI GPT-based models, or local summarization models) to process and generate summaries and prompt-based responses.6. Architecture & Design6.1 Overall Architecture- Frontend (Flutter Web):- Handles user interaction, UI, and integrates with JavaScript for media capture.- JavaScript Bridge:- Provides functions to start/stop recording and access audio streams.- Transcription & Analysis Module:- Either integrated client-side via WebAssembly or interfaced with a backend service for transcription and NLP functionalities.- For cloud transcription and NLP, this module makes RESTful API calls.- Export Module:- Handles local file creation and export (TXT, DOC, JSON) using browser storage APIs.6.2 Data Flow1. User Action:- The user initiates recording (microphone, system audio, or both).2. Audio Capture:- Browser APIs capture the desired audio streams.3. Recording & Storage:- Audio data is recorded using MediaRecorder and temporarily stored.4. Transcription & Analysis:- The recorded audio file is processed through the transcription module.- Optionally, once transcription is complete, an NLP module generates a summary or responds to a user’s prompt.5. Export:- Users can download the audio and/or transcription (or summarized transcript) files.7. User Interface & Experience7.1 Key UI Components- Dashboard/Home Screen:- Buttons to start/stop recording.- Indicators showing which sources are being recorded (mic, system).- Recording Screen:- Visual status (recording indicator, timer).- Options to pause/resume recording.- Transcription Screen:- Display the generated transcript.- Options to edit, download, or export the transcript.- Buttons for additional functions: Summarize Transcript, Enter Prompt for Analysis.- Analysis Screen (Future):- UI for entering custom prompts.- Display area for prompt-based responses (e.g., key takeaways, action items, etc.).- Settings:- Options for choosing transcription engine (offline vs. cloud).- Language selection.- Export format settings.- Toggle for enabling/disabling NLP summarization and prompt analysis.7.2 User Flow1. Launch Application:- User lands on the home screen.2. Configure Recording:- User chooses to record mic, system, or both.- If system audio is needed, instructions are provided to share the specific tab/screen.3. Record Meeting:- User initiates recording.- Audio is captured in real time.4. Transcribe:- After stopping the recording, the audio file is processed for transcription.5. Analysis (Future):- User can opt to generate a summary or enter a prompt for further analysis of the transcript.6. Export:- User exports the transcript, summary, and/or audio file.8. Data Storage & Export- Local File Storage:- Audio files stored in browser temporary storage or downloaded immediately.- Transcripts stored as plain text or JSON, with timestamp metadata.- Export Formats:- TXT for plain text.- DOC (or DOCX) for formatted text.- JSON for structured data (includes timestamps and possible speaker labels).9. Privacy & Security- Local Processing:- All audio, transcripts, and analysis data remain on the user's device unless explicitly exported.- Permission Handling:- Ensure the app clearly asks for permission to access the microphone and capture display/screen audio.- User Consent:- Include a disclaimer about the recording process, ensuring the user is aware of what is being captured and how it is processed.10. Limitations & Considerations- Browser Restrictions:- Directly capturing system audio (from a specific tab) requires using getDisplayMedia, which forces a screen-share prompt.- Some browsers or operating systems might restrict or alter the capabilities of getDisplayMedia.- Performance:- Real-time transcription and NLP summarization may be challenging if using heavier offline models on low-end hardware.- Cross-Browser Compatibility:- The application is optimized for Chromium-based browsers. Other browsers might require workarounds or have limited functionality.- NLP Capabilities:- Summarization and prompt-based analysis require additional compute. These may run on a backend service or using WebAssembly, and their latency and accuracy will need testing.11. Future Enhancements- Enhanced Real-Time Transcription:- Integrate more efficient models or cloud APIs to reduce latency.- Mobile Support:- Expand functionality via Flutter’s mobile deployment if mobile-specific audio capture becomes feasible.- UI Improvements:- Add features such as editing transcriptions, tagging speakers, or integration with calendar apps.- Browser Extension Integration:- Develop a companion browser extension to capture audio from any tab more seamlessly.- Transcript Summarization:- Develop and integrate NLP-based summarization that automatically condenses long transcripts into key points.- Prompt-Based Analysis:- Allow users to enter custom queries or prompts to get specific insights from the transcript (e.g., “List action items,” “Summarize decisions,” etc.).- Advanced Export Options:- Support more formats and integration with third-party services (e.g., cloud storage, collaboration tools).